{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best caption: A horse and a man standing\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import csv\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "from rouge_score import rouge_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CLIP processor and model\n",
    "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = [\"Image\", \"Reference_Captions\", \"Chosen_Caption\"]\n",
    "clip_predictions = []\n",
    "\n",
    "file_name = \"Test-Images.csv\"\n",
    "df = pd.read_csv(file_name)\n",
    "df = df.reset_index()\n",
    "\n",
    "root = \"./Predictions/\"\n",
    "\n",
    "vgg_predicted = root + \"VGG-Transformer.csv\"\n",
    "vgg_df = pd.read_csv(vgg_predicted)\n",
    "\n",
    "bilstm_predicted = root + \"ViT-BiLSTM.csv\"\n",
    "bilstm_df = pd.read_csv(bilstm_predicted)\n",
    "\n",
    "roberta_predicted = root + \"ViT-Roberta.csv\"\n",
    "roberta_df = pd.read_csv(roberta_predicted)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    image = row['Image']\n",
    "    actual_captions = row['Captions']\n",
    "\n",
    "    vgg = vgg_df[vgg_df['Image'] == image]['Caption'].iloc[0]\n",
    "    bilstm = bilstm_df[bilstm_df['Image'] == image]['Caption'].iloc[0]\n",
    "    roberta = roberta_df[roberta_df['Image'] == image]['Caption'].iloc[0]\n",
    "\n",
    "    candidate_captions = [vgg, bilstm, roberta]\n",
    "\n",
    "    inputs = clip_processor(text=candidate_captions, images=Image.open(image),\n",
    "                            return_tensors=\"pt\", padding=True)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = clip_model(**inputs)\n",
    "\n",
    "    # Extract logits\n",
    "    logits = outputs.logits_per_image  # Shape: (batch_size, num_labels)\n",
    "\n",
    "    # Find the index of the highest-scoring caption\n",
    "    best_caption_index = torch.argmax(logits).item()\n",
    "    best_caption = candidate_captions[best_caption_index]\n",
    "\n",
    "    temp = [image, actual_captions, best_caption]\n",
    "    clip_predictions.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_predictions_file_name = \"Clip-Predictions.csv\"\n",
    "\n",
    "with open(clip_predictions_file_name, 'w', newline = \"\") as file:\n",
    "    csvwriter = csv.writer(file)\n",
    "    csvwriter.writerow(header)\n",
    "    csvwriter.writerows(clip_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_df = pd.read_csv(clip_predictions_file_name)\n",
    "clip_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating blue scores\n",
    "\n",
    "bleu1 = 0\n",
    "bleu2 = 0\n",
    "bleu3 = 0\n",
    "bleu4 = 0\n",
    "mod = 1e9 + 7\n",
    "length = 1000\n",
    "\n",
    "for index, row in clip_df.iterrows():\n",
    "    reference_captions = row[\"Reference_Captions\"]\n",
    "    reference_captions_list = [element.split() for element in reference_captions]\n",
    "    candidate_caption = row[\"Chosen_Caption\"]\n",
    "    candidate_caption_list = candidate_caption.split()\n",
    "    bleu1 = (bleu1 + sentence_bleu(reference_captions_list, candidate_caption_list, weights=(1.0,0,0,0))) % mod\n",
    "    bleu2 = (bleu2 + sentence_bleu(reference_captions_list, candidate_caption_list, weights=(0.5,0.5,0,0))) % mod\n",
    "    bleu3 = (bleu3 + sentence_bleu(reference_captions_list, candidate_caption_list, weights=(0.3,0.3,0.3,0))) % mod\n",
    "    bleu4 = (bleu4 + sentence_bleu(reference_captions_list, candidate_caption_list, weights=(0.25,0.25,0.25,0.25))) % mod\n",
    "\n",
    "\n",
    "print(f\"BLEU-1 score: {(bleu1/length) * 100}\")\n",
    "print(f\"BLEU-2 score: {(bleu2/length) * 100}\")\n",
    "print(f\"BLEU-3 score: {(bleu3/length) * 100}\")\n",
    "print(f\"BLEU-4 score: {(bleu4/length) * 100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating meteor metric\n",
    "\n",
    "meteor = 0\n",
    "length = 1000\n",
    "mod = 1e9 + 7\n",
    "\n",
    "for index, row in clip_df.iterrows():\n",
    "    reference_captions = row[\"Reference_Captions\"]\n",
    "    reference_captions_list = [element.split() for element in reference_captions]\n",
    "    candidate_caption = row[\"Chosen_Caption\"]\n",
    "    candidate_caption_list = candidate_caption.split()\n",
    "    meteor = (meteor + meteor_score(reference_captions_list, candidate_caption_list)) % mod\n",
    "\n",
    "print(f\"METEOR score: {(meteor/length) * 100}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating rouge metric\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "rouge1_precision = 0\n",
    "rouge1_recall = 0\n",
    "rouge1_fmeasure = 0\n",
    "rouge2_precision = 0\n",
    "rouge2_recall = 0\n",
    "rouge2_fmeasure = 0\n",
    "rougeL_precision = 0\n",
    "rougeL_recall = 0\n",
    "rougeL_fmeasure = 0\n",
    "\n",
    "obj = {\n",
    "    'rouge1': [0, 0, 0],\n",
    "    'rouge2': [0, 0, 0],\n",
    "    'rougeL': [0, 0, 0]\n",
    "}\n",
    "\n",
    "for index, row in clip_df.iterrows():\n",
    "    reference_captions = row[\"Reference_Captions\"]\n",
    "    candidate_caption = row[\"Chosen_Caption\"]\n",
    "    scores = {key: [] for key in ['rouge1', 'rouge2', 'rougeL']}\n",
    "    r1_p_max = 0\n",
    "    r1_r_max = 0\n",
    "    r1_f_max = 0\n",
    "    r2_p_max = 0\n",
    "    r2_r_max = 0\n",
    "    r2_f_max = 0\n",
    "    rL_p_max = 0\n",
    "    rL_r_max = 0\n",
    "    rL_f_max = 0\n",
    "    for ref in reference_captions:\n",
    "        temp_scores = scorer.score(ref, candidate_caption)\n",
    "        r1_p_max = max(r1_p_max, temp_scores['rouge1'].precision)\n",
    "        r1_r_max = max(r1_r_max, temp_scores['rouge1'].recall)\n",
    "        r1_f_max = max(r1_f_max, temp_scores['rouge1'].fmeasure)\n",
    "\n",
    "        r2_p_max = max(r2_p_max, temp_scores['rouge2'].precision)\n",
    "        r2_r_max = max(r2_r_max, temp_scores['rouge2'].recall)\n",
    "        r2_f_max = max(r2_f_max, temp_scores['rouge2'].fmeasure)\n",
    "\n",
    "        rL_p_max = max(rL_p_max, temp_scores['rougeL'].precision)\n",
    "        rL_r_max = max(rL_r_max, temp_scores['rougeL'].recall)\n",
    "        rL_f_max = max(rL_f_max, temp_scores['rougeL'].fmeasure)\n",
    "        \n",
    "    obj['rouge1'][0] = (obj['rouge1'][0] + r1_p_max) % mod\n",
    "    obj['rouge1'][1] = (obj['rouge1'][1] + r1_r_max) % mod\n",
    "    obj['rouge1'][2] = (obj['rouge1'][2] + r1_f_max) % mod\n",
    "    obj['rouge2'][0] = (obj['rouge2'][0] + r2_p_max) % mod\n",
    "    obj['rouge2'][1] = (obj['rouge2'][1] + r2_r_max) % mod\n",
    "    obj['rouge2'][2] = (obj['rouge2'][2] + r2_f_max) % mod\n",
    "    obj['rougeL'][0] = (obj['rougeL'][0] + rL_p_max) % mod\n",
    "    obj['rougeL'][1] = (obj['rougeL'][1] + rL_r_max) % mod\n",
    "    obj['rougeL'][2] = (obj['rougeL'][2] + rL_f_max) % mod\n",
    "\n",
    "\n",
    "size = length\n",
    "print(f'Rouge1: Precision = {obj[\"rouge1\"][0] * 100 / size}, Recall = {obj[\"rouge1\"][1] * 100 / size}, f_measure = {obj[\"rouge1\"][2] * 100 / size}')\n",
    "print(f'Rouge2: Precision = {obj[\"rouge2\"][0] * 100 / size}, Recall = {obj[\"rouge2\"][1] * 100 / size}, f_measure = {obj[\"rouge2\"][2] * 100 / size}')\n",
    "print(f'RougeL: Precision = {obj[\"rougeL\"][0] * 100 / size}, Recall = {obj[\"rougeL\"][1] * 100 / size}, f_measure = {obj[\"rougeL\"][2] * 100 / size}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vitbilstm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
